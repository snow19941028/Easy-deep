{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics of MLP\n",
    "- Objective: create vanilla neural networks (i.e., Multilayer perceptrons) for simple regression/classification tasks with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Structures\n",
    "- Each MLP model is consisted of one input layer, several hidden layers, and one output layer\n",
    "- Number of neurons in each layer is not limited\n",
    "<img src=\"http://cs231n.github.io/assets/nn1/neural_net.jpeg\" style=\"width: 300px\"/>\n",
    "<br>\n",
    "<center>**MLP with one hidden layer**</center>\n",
    "- Number of input neurons: 3\n",
    "- Number of hidden neurons: 4\n",
    "- Number of output neurons: 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://cs231n.github.io/assets/nn1/neural_net2.jpeg\" style=\"width: 500px\"/>\n",
    "<br>\n",
    "<center>**MLP with two hidden layers**</center>\n",
    "- Number of input neurons: 3\n",
    "- Number of hidden neurons: (4, 4)\n",
    "- Number of output neurons: 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP for Regression tasks\n",
    "- When the target (**y**) is continuous (real)\n",
    "- For loss function and evaluation metric, mean squared error (MSE) is commonly used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import boston_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Description\n",
    "- Boston housing dataset has total 506 data instances (404 training & 102 test)\n",
    "- 13 attributes (features) to predict \"the median values of the houses at a location\"\n",
    "- Doc: https://keras.io/datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404, 13)\n",
      "(102, 13)\n",
      "(404,)\n",
      "(102,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Creating a model\n",
    "- Keras model object can be created with Sequential class\n",
    "- At the outset, the model is empty per se. It is completed by **'adding'** additional layers and compilation\n",
    "- Doc: https://keras.io/models/sequential/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1. Adding layers\n",
    "- Keras layers can be **added** to the model\n",
    "- Adding layers are like stacking lego blocks one by one\n",
    "- Doc: https://keras.io/layers/core/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Activation, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Keras model with two hidden layer with 10 neurons each \n",
    "model.add(Dense(10, input_shape = (13,)))    # Input layer => input_shape should be explicitly designated\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(10))                         # Hidden layer => only output dimension should be designated\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(10))                         # Hidden layer => only output dimension should be designated\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(1))                          # Output layer => output dimension = 1 since it is regression problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is equivalent to the above code block\n",
    "model.add(Dense(10, input_shape = (13,), activation = 'sigmoid'))\n",
    "model.add(Dense(10, activation = 'sigmoid'))\n",
    "model.add(Dense(10, activation = 'sigmoid'))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2. Model compile\n",
    "- Keras model should be \"compiled\" prior to training\n",
    "- Types of loss (function) and optimizer should be designated\n",
    "    - Doc (optimizers): https://keras.io/optimizers/\n",
    "    - Doc (losses): https://keras.io/losses/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd = optimizers.SGD(lr = 0.01)    # stochastic gradient descent optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = sgd, loss = 'mean_squared_error', metrics = ['mse'])    # for regression problems, mean squared error (MSE) is often employed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 10)                140       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 371\n",
      "Trainable params: 371\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Training\n",
    "- Training the model with training data provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "404/404 [==============================] - 0s - loss: 334.3073 - mean_squared_error: 334.3073     \n",
      "Epoch 2/100\n",
      "404/404 [==============================] - 0s - loss: 87.3343 - mean_squared_error: 87.3343     \n",
      "Epoch 3/100\n",
      "404/404 [==============================] - 0s - loss: 82.3100 - mean_squared_error: 82.3100     \n",
      "Epoch 4/100\n",
      "404/404 [==============================] - 0s - loss: 81.8316 - mean_squared_error: 81.8316     \n",
      "Epoch 5/100\n",
      "404/404 [==============================] - 0s - loss: 82.4353 - mean_squared_error: 82.4353     \n",
      "Epoch 6/100\n",
      "404/404 [==============================] - 0s - loss: 80.6487 - mean_squared_error: 80.6487       \n",
      "Epoch 7/100\n",
      "404/404 [==============================] - 0s - loss: 79.5000 - mean_squared_error: 79.5000     \n",
      "Epoch 8/100\n",
      "404/404 [==============================] - 0s - loss: 79.0343 - mean_squared_error: 79.0343     \n",
      "Epoch 9/100\n",
      "404/404 [==============================] - 0s - loss: 77.8822 - mean_squared_error: 77.8822     \n",
      "Epoch 10/100\n",
      "404/404 [==============================] - 0s - loss: 77.4633 - mean_squared_error: 77.4633     \n",
      "Epoch 11/100\n",
      "404/404 [==============================] - 0s - loss: 75.5106 - mean_squared_error: 75.5106     \n",
      "Epoch 12/100\n",
      "404/404 [==============================] - 0s - loss: 75.5629 - mean_squared_error: 75.5629     \n",
      "Epoch 13/100\n",
      "404/404 [==============================] - 0s - loss: 77.3433 - mean_squared_error: 77.3433     \n",
      "Epoch 14/100\n",
      "404/404 [==============================] - 0s - loss: 75.7194 - mean_squared_error: 75.7194     \n",
      "Epoch 15/100\n",
      "404/404 [==============================] - 0s - loss: 81.1020 - mean_squared_error: 81.1020     \n",
      "Epoch 16/100\n",
      "404/404 [==============================] - 0s - loss: 80.5553 - mean_squared_error: 80.5553       \n",
      "Epoch 17/100\n",
      "404/404 [==============================] - 0s - loss: 82.1620 - mean_squared_error: 82.1620     \n",
      "Epoch 18/100\n",
      "404/404 [==============================] - 0s - loss: 84.0061 - mean_squared_error: 84.0061       \n",
      "Epoch 19/100\n",
      "404/404 [==============================] - 0s - loss: 82.7542 - mean_squared_error: 82.7542     \n",
      "Epoch 20/100\n",
      "404/404 [==============================] - 0s - loss: 82.0314 - mean_squared_error: 82.0314     \n",
      "Epoch 21/100\n",
      "404/404 [==============================] - 0s - loss: 81.8394 - mean_squared_error: 81.8394     \n",
      "Epoch 22/100\n",
      "404/404 [==============================] - 0s - loss: 82.4158 - mean_squared_error: 82.4158     \n",
      "Epoch 23/100\n",
      "404/404 [==============================] - 0s - loss: 81.5277 - mean_squared_error: 81.5277     \n",
      "Epoch 24/100\n",
      "404/404 [==============================] - 0s - loss: 82.1193 - mean_squared_error: 82.1193     \n",
      "Epoch 25/100\n",
      "404/404 [==============================] - 0s - loss: 82.0086 - mean_squared_error: 82.0086     \n",
      "Epoch 26/100\n",
      "404/404 [==============================] - 0s - loss: 82.0210 - mean_squared_error: 82.0210     \n",
      "Epoch 27/100\n",
      "404/404 [==============================] - 0s - loss: 81.5607 - mean_squared_error: 81.5607     \n",
      "Epoch 28/100\n",
      "404/404 [==============================] - 0s - loss: 83.9326 - mean_squared_error: 83.9326       \n",
      "Epoch 29/100\n",
      "404/404 [==============================] - 0s - loss: 81.0824 - mean_squared_error: 81.0824     \n",
      "Epoch 30/100\n",
      "404/404 [==============================] - 0s - loss: 80.8668 - mean_squared_error: 80.8668     \n",
      "Epoch 31/100\n",
      "404/404 [==============================] - 0s - loss: 81.1916 - mean_squared_error: 81.1916     \n",
      "Epoch 32/100\n",
      "404/404 [==============================] - 0s - loss: 85.1976 - mean_squared_error: 85.1976       \n",
      "Epoch 33/100\n",
      "404/404 [==============================] - 0s - loss: 85.2691 - mean_squared_error: 85.2691     \n",
      "Epoch 34/100\n",
      "404/404 [==============================] - 0s - loss: 83.2262 - mean_squared_error: 83.2262       \n",
      "Epoch 35/100\n",
      "404/404 [==============================] - 0s - loss: 80.1518 - mean_squared_error: 80.1518       \n",
      "Epoch 36/100\n",
      "404/404 [==============================] - 0s - loss: 79.7113 - mean_squared_error: 79.7113       \n",
      "Epoch 37/100\n",
      "404/404 [==============================] - 0s - loss: 79.7037 - mean_squared_error: 79.7037     \n",
      "Epoch 38/100\n",
      "404/404 [==============================] - 0s - loss: 82.9349 - mean_squared_error: 82.9349       \n",
      "Epoch 39/100\n",
      "404/404 [==============================] - 0s - loss: 79.9645 - mean_squared_error: 79.9645     \n",
      "Epoch 40/100\n",
      "404/404 [==============================] - 0s - loss: 81.0910 - mean_squared_error: 81.0910     \n",
      "Epoch 41/100\n",
      "404/404 [==============================] - 0s - loss: 80.2282 - mean_squared_error: 80.2282     \n",
      "Epoch 42/100\n",
      "404/404 [==============================] - 0s - loss: 79.1687 - mean_squared_error: 79.1687     \n",
      "Epoch 43/100\n",
      "404/404 [==============================] - 0s - loss: 79.4841 - mean_squared_error: 79.4841     \n",
      "Epoch 44/100\n",
      "404/404 [==============================] - 0s - loss: 79.9736 - mean_squared_error: 79.9736     \n",
      "Epoch 45/100\n",
      "404/404 [==============================] - 0s - loss: 80.2017 - mean_squared_error: 80.2017     \n",
      "Epoch 46/100\n",
      "404/404 [==============================] - 0s - loss: 78.5571 - mean_squared_error: 78.5571     \n",
      "Epoch 47/100\n",
      "404/404 [==============================] - 0s - loss: 79.0746 - mean_squared_error: 79.0746     \n",
      "Epoch 48/100\n",
      "404/404 [==============================] - 0s - loss: 78.6022 - mean_squared_error: 78.6022     \n",
      "Epoch 49/100\n",
      "404/404 [==============================] - 0s - loss: 78.5750 - mean_squared_error: 78.5750     \n",
      "Epoch 50/100\n",
      "404/404 [==============================] - 0s - loss: 79.1593 - mean_squared_error: 79.1593       \n",
      "Epoch 51/100\n",
      "404/404 [==============================] - 0s - loss: 80.0401 - mean_squared_error: 80.0401     \n",
      "Epoch 52/100\n",
      "404/404 [==============================] - 0s - loss: 78.9750 - mean_squared_error: 78.9750     \n",
      "Epoch 53/100\n",
      "404/404 [==============================] - 0s - loss: 78.8663 - mean_squared_error: 78.8663     \n",
      "Epoch 54/100\n",
      "404/404 [==============================] - 0s - loss: 78.7844 - mean_squared_error: 78.7844     \n",
      "Epoch 55/100\n",
      "404/404 [==============================] - 0s - loss: 78.0640 - mean_squared_error: 78.0640     \n",
      "Epoch 56/100\n",
      "404/404 [==============================] - 0s - loss: 79.9396 - mean_squared_error: 79.9396     \n",
      "Epoch 57/100\n",
      "404/404 [==============================] - 0s - loss: 78.6382 - mean_squared_error: 78.6382     \n",
      "Epoch 58/100\n",
      "404/404 [==============================] - 0s - loss: 78.6881 - mean_squared_error: 78.6881     \n",
      "Epoch 59/100\n",
      "404/404 [==============================] - 0s - loss: 77.4692 - mean_squared_error: 77.4692     \n",
      "Epoch 60/100\n",
      "404/404 [==============================] - 0s - loss: 78.2065 - mean_squared_error: 78.2065     \n",
      "Epoch 61/100\n",
      "404/404 [==============================] - 0s - loss: 77.7867 - mean_squared_error: 77.7867     \n",
      "Epoch 62/100\n",
      "404/404 [==============================] - 0s - loss: 79.4284 - mean_squared_error: 79.4284     \n",
      "Epoch 63/100\n",
      "404/404 [==============================] - 0s - loss: 78.2600 - mean_squared_error: 78.2600     \n",
      "Epoch 64/100\n",
      "404/404 [==============================] - 0s - loss: 77.5778 - mean_squared_error: 77.5778     \n",
      "Epoch 65/100\n",
      "404/404 [==============================] - 0s - loss: 78.3338 - mean_squared_error: 78.3338     \n",
      "Epoch 66/100\n",
      "404/404 [==============================] - 0s - loss: 77.4813 - mean_squared_error: 77.4813       \n",
      "Epoch 67/100\n",
      "404/404 [==============================] - 0s - loss: 77.6497 - mean_squared_error: 77.6497     \n",
      "Epoch 68/100\n",
      "404/404 [==============================] - 0s - loss: 78.7006 - mean_squared_error: 78.7006     \n",
      "Epoch 69/100\n",
      "404/404 [==============================] - 0s - loss: 78.0871 - mean_squared_error: 78.0871     \n",
      "Epoch 70/100\n",
      "404/404 [==============================] - 0s - loss: 77.3485 - mean_squared_error: 77.3485     \n",
      "Epoch 71/100\n",
      "404/404 [==============================] - 0s - loss: 77.8501 - mean_squared_error: 77.8501     \n",
      "Epoch 72/100\n",
      "404/404 [==============================] - 0s - loss: 77.6599 - mean_squared_error: 77.6599     \n",
      "Epoch 73/100\n",
      "404/404 [==============================] - 0s - loss: 77.2750 - mean_squared_error: 77.2750     \n",
      "Epoch 74/100\n",
      "404/404 [==============================] - 0s - loss: 77.3181 - mean_squared_error: 77.3181     \n",
      "Epoch 75/100\n",
      "404/404 [==============================] - 0s - loss: 78.6509 - mean_squared_error: 78.6509     \n",
      "Epoch 76/100\n",
      "404/404 [==============================] - 0s - loss: 78.9403 - mean_squared_error: 78.9403       \n",
      "Epoch 77/100\n",
      "404/404 [==============================] - 0s - loss: 78.2378 - mean_squared_error: 78.2378     \n",
      "Epoch 78/100\n",
      "404/404 [==============================] - 0s - loss: 77.2291 - mean_squared_error: 77.2291     \n",
      "Epoch 79/100\n",
      "404/404 [==============================] - 0s - loss: 78.0758 - mean_squared_error: 78.0758     \n",
      "Epoch 80/100\n",
      "404/404 [==============================] - 0s - loss: 79.8132 - mean_squared_error: 79.8132       \n",
      "Epoch 81/100\n",
      "404/404 [==============================] - 0s - loss: 77.7784 - mean_squared_error: 77.7784     \n",
      "Epoch 82/100\n",
      "404/404 [==============================] - 0s - loss: 77.8923 - mean_squared_error: 77.8923     \n",
      "Epoch 83/100\n",
      "404/404 [==============================] - 0s - loss: 77.6668 - mean_squared_error: 77.6668     \n",
      "Epoch 84/100\n",
      "404/404 [==============================] - 0s - loss: 77.3130 - mean_squared_error: 77.3130     \n",
      "Epoch 85/100\n",
      "404/404 [==============================] - 0s - loss: 77.2655 - mean_squared_error: 77.2655     \n",
      "Epoch 86/100\n",
      "404/404 [==============================] - 0s - loss: 76.7503 - mean_squared_error: 76.7503     \n",
      "Epoch 87/100\n",
      "404/404 [==============================] - 0s - loss: 78.4088 - mean_squared_error: 78.4088     \n",
      "Epoch 88/100\n",
      "404/404 [==============================] - 0s - loss: 77.7564 - mean_squared_error: 77.7564     \n",
      "Epoch 89/100\n",
      "404/404 [==============================] - 0s - loss: 78.2782 - mean_squared_error: 78.2782       \n",
      "Epoch 90/100\n",
      "404/404 [==============================] - 0s - loss: 77.3601 - mean_squared_error: 77.3601     \n",
      "Epoch 91/100\n",
      "404/404 [==============================] - 0s - loss: 78.7650 - mean_squared_error: 78.7650       \n",
      "Epoch 92/100\n",
      "404/404 [==============================] - 0s - loss: 77.4081 - mean_squared_error: 77.4081     \n",
      "Epoch 93/100\n",
      "404/404 [==============================] - 0s - loss: 77.6047 - mean_squared_error: 77.6047     \n",
      "Epoch 94/100\n",
      "404/404 [==============================] - 0s - loss: 78.1817 - mean_squared_error: 78.1817     \n",
      "Epoch 95/100\n",
      "404/404 [==============================] - 0s - loss: 77.8141 - mean_squared_error: 77.8141       \n",
      "Epoch 96/100\n",
      "404/404 [==============================] - 0s - loss: 77.5291 - mean_squared_error: 77.5291     \n",
      "Epoch 97/100\n",
      "404/404 [==============================] - 0s - loss: 77.8513 - mean_squared_error: 77.8513     \n",
      "Epoch 98/100\n",
      "404/404 [==============================] - 0s - loss: 77.6128 - mean_squared_error: 77.6128     \n",
      "Epoch 99/100\n",
      "404/404 [==============================] - 0s - loss: 77.6937 - mean_squared_error: 77.6937     \n",
      "Epoch 100/100\n",
      "404/404 [==============================] - 0s - loss: 77.1717 - mean_squared_error: 77.1717       \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25df744e080>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size = 50, epochs = 100, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Evaluation\n",
    "- Keras model can be evaluated with evaluate() function\n",
    "- Evaluation results are contained in a list\n",
    "    - Doc (metrics): https://keras.io/metrics/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 32/102 [========>.....................] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'mean_squared_error']\n",
      "[81.900110581341906, 81.900110581341906]\n"
     ]
    }
   ],
   "source": [
    "print(model.metrics_names)     # list of metric names the model is employing\n",
    "print(results)                 # actual figure of metrics computed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  81.9001105813\n",
      "mse:  81.9001105813\n"
     ]
    }
   ],
   "source": [
    "print('loss: ', results[0])\n",
    "print('mse: ', results[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP for classification tasks\n",
    "- When the target (**y**) is discrete (categorical)\n",
    "- For loss function, cross-entropy is used and for evaluation metric, accuracy is commonly used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "whole_data = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_data = whole_data.data\n",
    "y_data = whole_data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size = 0.3, random_state = 7) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Description\n",
    "- Breast cancer dataset has total 569 data instances (212 malign, 357 benign instances)\n",
    "- 30 attributes (features) to predict the binary class (M/B)\n",
    "- Doc: http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html#sklearn.datasets.load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(398, 30)\n",
      "(171, 30)\n",
      "(398,)\n",
      "(171,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Creating a model\n",
    "- Same with regression model at the outset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1. Adding layers\n",
    "- Keras layers can be **added** to the model\n",
    "- Adding layers are like stacking lego blocks one by one\n",
    "- It should be noted that as this is a classification problem, sigmoid layer (softmax for multi-class problems) should be added\n",
    "- Doc: https://keras.io/layers/core/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Keras model with two hidden layer with 10 neurons each \n",
    "model.add(Dense(10, input_shape = (30,)))    # Input layer => input_shape should be explicitly designated\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(10))                         # Hidden layer => only output dimension should be designated\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(10))                         # Hidden layer => only output dimension should be designated\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(1))                          # Output layer => output dimension = 1 since it is regression problem\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is equivalent to the above code block\n",
    "model.add(Dense(10, input_shape = (13,), activation = 'sigmoid'))\n",
    "model.add(Dense(10, activation = 'sigmoid'))\n",
    "model.add(Dense(10, activation = 'sigmoid'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2. Model compile\n",
    "- Keras model should be \"compiled\" prior to training\n",
    "- Types of loss (function) and optimizer should be designated\n",
    "    - Doc (optimizers): https://keras.io/optimizers/\n",
    "    - Doc (losses): https://keras.io/losses/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd = optimizers.SGD(lr = 0.01)    # stochastic gradient descent optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = sgd, loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 10)                310       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 11        \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 541\n",
      "Trainable params: 541\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Training\n",
    "- Training the model with training data provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "398/398 [==============================] - 0s - loss: 0.7938 - acc: 0.3945     \n",
      "Epoch 2/100\n",
      "398/398 [==============================] - 0s - loss: 0.7761 - acc: 0.3945     \n",
      "Epoch 3/100\n",
      "398/398 [==============================] - 0s - loss: 0.7609 - acc: 0.3945     \n",
      "Epoch 4/100\n",
      "398/398 [==============================] - 0s - loss: 0.7478 - acc: 0.3945     \n",
      "Epoch 5/100\n",
      "398/398 [==============================] - 0s - loss: 0.7366 - acc: 0.3945     \n",
      "Epoch 6/100\n",
      "398/398 [==============================] - 0s - loss: 0.7270 - acc: 0.3945     \n",
      "Epoch 7/100\n",
      "398/398 [==============================] - 0s - loss: 0.7188 - acc: 0.3945     \n",
      "Epoch 8/100\n",
      "398/398 [==============================] - 0s - loss: 0.7117 - acc: 0.3945     \n",
      "Epoch 9/100\n",
      "398/398 [==============================] - 0s - loss: 0.7057 - acc: 0.3945     \n",
      "Epoch 10/100\n",
      "398/398 [==============================] - 0s - loss: 0.7007 - acc: 0.3945     \n",
      "Epoch 11/100\n",
      "398/398 [==============================] - 0s - loss: 0.6962 - acc: 0.3945     \n",
      "Epoch 12/100\n",
      "398/398 [==============================] - 0s - loss: 0.6926 - acc: 0.5427     \n",
      "Epoch 13/100\n",
      "398/398 [==============================] - 0s - loss: 0.6895 - acc: 0.6055     \n",
      "Epoch 14/100\n",
      "398/398 [==============================] - 0s - loss: 0.6869 - acc: 0.6055     \n",
      "Epoch 15/100\n",
      "398/398 [==============================] - 0s - loss: 0.6846 - acc: 0.6055     \n",
      "Epoch 16/100\n",
      "398/398 [==============================] - 0s - loss: 0.6826 - acc: 0.6055     \n",
      "Epoch 17/100\n",
      "398/398 [==============================] - 0s - loss: 0.6808 - acc: 0.6055     \n",
      "Epoch 18/100\n",
      "398/398 [==============================] - 0s - loss: 0.6794 - acc: 0.6055     \n",
      "Epoch 19/100\n",
      "398/398 [==============================] - 0s - loss: 0.6782 - acc: 0.6055     \n",
      "Epoch 20/100\n",
      "398/398 [==============================] - 0s - loss: 0.6771 - acc: 0.6055     \n",
      "Epoch 21/100\n",
      "398/398 [==============================] - 0s - loss: 0.6760 - acc: 0.6055     \n",
      "Epoch 22/100\n",
      "398/398 [==============================] - 0s - loss: 0.6753 - acc: 0.6055     \n",
      "Epoch 23/100\n",
      "398/398 [==============================] - 0s - loss: 0.6746 - acc: 0.6055     \n",
      "Epoch 24/100\n",
      "398/398 [==============================] - 0s - loss: 0.6740 - acc: 0.6055     \n",
      "Epoch 25/100\n",
      "398/398 [==============================] - 0s - loss: 0.6735 - acc: 0.6055     \n",
      "Epoch 26/100\n",
      "398/398 [==============================] - 0s - loss: 0.6730 - acc: 0.6055     \n",
      "Epoch 27/100\n",
      "398/398 [==============================] - 0s - loss: 0.6727 - acc: 0.6055     \n",
      "Epoch 28/100\n",
      "398/398 [==============================] - 0s - loss: 0.6724 - acc: 0.6055     \n",
      "Epoch 29/100\n",
      "398/398 [==============================] - 0s - loss: 0.6721 - acc: 0.6055     \n",
      "Epoch 30/100\n",
      "398/398 [==============================] - 0s - loss: 0.6719 - acc: 0.6055     \n",
      "Epoch 31/100\n",
      "398/398 [==============================] - 0s - loss: 0.6716 - acc: 0.6055     \n",
      "Epoch 32/100\n",
      "398/398 [==============================] - 0s - loss: 0.6714 - acc: 0.6055     \n",
      "Epoch 33/100\n",
      "398/398 [==============================] - 0s - loss: 0.6713 - acc: 0.6055     \n",
      "Epoch 34/100\n",
      "398/398 [==============================] - 0s - loss: 0.6711 - acc: 0.6055     \n",
      "Epoch 35/100\n",
      "398/398 [==============================] - 0s - loss: 0.6710 - acc: 0.6055     \n",
      "Epoch 36/100\n",
      "398/398 [==============================] - 0s - loss: 0.6709 - acc: 0.6055     \n",
      "Epoch 37/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 38/100\n",
      "398/398 [==============================] - 0s - loss: 0.6708 - acc: 0.6055     \n",
      "Epoch 39/100\n",
      "398/398 [==============================] - 0s - loss: 0.6706 - acc: 0.6055     \n",
      "Epoch 40/100\n",
      "398/398 [==============================] - 0s - loss: 0.6706 - acc: 0.6055     \n",
      "Epoch 41/100\n",
      "398/398 [==============================] - 0s - loss: 0.6705 - acc: 0.6055     \n",
      "Epoch 42/100\n",
      "398/398 [==============================] - 0s - loss: 0.6706 - acc: 0.6055     \n",
      "Epoch 43/100\n",
      "398/398 [==============================] - 0s - loss: 0.6705 - acc: 0.6055     \n",
      "Epoch 44/100\n",
      "398/398 [==============================] - 0s - loss: 0.6704 - acc: 0.6055     \n",
      "Epoch 45/100\n",
      "398/398 [==============================] - 0s - loss: 0.6704 - acc: 0.6055     \n",
      "Epoch 46/100\n",
      "398/398 [==============================] - 0s - loss: 0.6704 - acc: 0.6055     \n",
      "Epoch 47/100\n",
      "398/398 [==============================] - 0s - loss: 0.6703 - acc: 0.6055     \n",
      "Epoch 48/100\n",
      "398/398 [==============================] - 0s - loss: 0.6702 - acc: 0.6055     \n",
      "Epoch 49/100\n",
      "398/398 [==============================] - 0s - loss: 0.6703 - acc: 0.6055     \n",
      "Epoch 50/100\n",
      "398/398 [==============================] - 0s - loss: 0.6702 - acc: 0.6055     \n",
      "Epoch 51/100\n",
      "398/398 [==============================] - 0s - loss: 0.6703 - acc: 0.6055     \n",
      "Epoch 52/100\n",
      "398/398 [==============================] - 0s - loss: 0.6703 - acc: 0.6055     \n",
      "Epoch 53/100\n",
      "398/398 [==============================] - 0s - loss: 0.6702 - acc: 0.6055     \n",
      "Epoch 54/100\n",
      "398/398 [==============================] - 0s - loss: 0.6702 - acc: 0.6055     \n",
      "Epoch 55/100\n",
      "398/398 [==============================] - 0s - loss: 0.6702 - acc: 0.6055     \n",
      "Epoch 56/100\n",
      "398/398 [==============================] - 0s - loss: 0.6702 - acc: 0.6055     \n",
      "Epoch 57/100\n",
      "398/398 [==============================] - 0s - loss: 0.6701 - acc: 0.6055     \n",
      "Epoch 58/100\n",
      "398/398 [==============================] - 0s - loss: 0.6701 - acc: 0.6055     \n",
      "Epoch 59/100\n",
      "398/398 [==============================] - 0s - loss: 0.6702 - acc: 0.6055     \n",
      "Epoch 60/100\n",
      "398/398 [==============================] - 0s - loss: 0.6700 - acc: 0.6055     \n",
      "Epoch 61/100\n",
      "398/398 [==============================] - 0s - loss: 0.6700 - acc: 0.6055     \n",
      "Epoch 62/100\n",
      "398/398 [==============================] - 0s - loss: 0.6700 - acc: 0.6055     \n",
      "Epoch 63/100\n",
      "398/398 [==============================] - 0s - loss: 0.6701 - acc: 0.6055     \n",
      "Epoch 64/100\n",
      "398/398 [==============================] - 0s - loss: 0.6700 - acc: 0.6055     \n",
      "Epoch 65/100\n",
      "398/398 [==============================] - 0s - loss: 0.6700 - acc: 0.6055     \n",
      "Epoch 66/100\n",
      "398/398 [==============================] - 0s - loss: 0.6699 - acc: 0.6055     \n",
      "Epoch 67/100\n",
      "398/398 [==============================] - 0s - loss: 0.6699 - acc: 0.6055     \n",
      "Epoch 68/100\n",
      "398/398 [==============================] - 0s - loss: 0.6700 - acc: 0.6055     \n",
      "Epoch 69/100\n",
      "398/398 [==============================] - 0s - loss: 0.6699 - acc: 0.6055     \n",
      "Epoch 70/100\n",
      "398/398 [==============================] - 0s - loss: 0.6699 - acc: 0.6055     \n",
      "Epoch 71/100\n",
      "398/398 [==============================] - 0s - loss: 0.6700 - acc: 0.6055     \n",
      "Epoch 72/100\n",
      "398/398 [==============================] - 0s - loss: 0.6699 - acc: 0.6055     \n",
      "Epoch 73/100\n",
      "398/398 [==============================] - 0s - loss: 0.6700 - acc: 0.6055     \n",
      "Epoch 74/100\n",
      "398/398 [==============================] - 0s - loss: 0.6699 - acc: 0.6055     \n",
      "Epoch 75/100\n",
      "398/398 [==============================] - 0s - loss: 0.6698 - acc: 0.6055     \n",
      "Epoch 76/100\n",
      "398/398 [==============================] - 0s - loss: 0.6698 - acc: 0.6055     \n",
      "Epoch 77/100\n",
      "398/398 [==============================] - 0s - loss: 0.6698 - acc: 0.6055     \n",
      "Epoch 78/100\n",
      "398/398 [==============================] - 0s - loss: 0.6698 - acc: 0.6055     \n",
      "Epoch 79/100\n",
      "398/398 [==============================] - 0s - loss: 0.6698 - acc: 0.6055     \n",
      "Epoch 80/100\n",
      "398/398 [==============================] - 0s - loss: 0.6698 - acc: 0.6055     \n",
      "Epoch 81/100\n",
      "398/398 [==============================] - 0s - loss: 0.6698 - acc: 0.6055     \n",
      "Epoch 82/100\n",
      "398/398 [==============================] - 0s - loss: 0.6698 - acc: 0.6055     \n",
      "Epoch 83/100\n",
      "398/398 [==============================] - 0s - loss: 0.6698 - acc: 0.6055     \n",
      "Epoch 84/100\n",
      "398/398 [==============================] - 0s - loss: 0.6697 - acc: 0.6055     \n",
      "Epoch 85/100\n",
      "398/398 [==============================] - 0s - loss: 0.6697 - acc: 0.6055     \n",
      "Epoch 86/100\n",
      "398/398 [==============================] - 0s - loss: 0.6697 - acc: 0.6055     \n",
      "Epoch 87/100\n",
      "398/398 [==============================] - 0s - loss: 0.6696 - acc: 0.6055     \n",
      "Epoch 88/100\n",
      "398/398 [==============================] - 0s - loss: 0.6697 - acc: 0.6055     \n",
      "Epoch 89/100\n",
      "398/398 [==============================] - 0s - loss: 0.6697 - acc: 0.6055     \n",
      "Epoch 90/100\n",
      "398/398 [==============================] - 0s - loss: 0.6697 - acc: 0.6055     \n",
      "Epoch 91/100\n",
      "398/398 [==============================] - 0s - loss: 0.6696 - acc: 0.6055     \n",
      "Epoch 92/100\n",
      "398/398 [==============================] - 0s - loss: 0.6696 - acc: 0.6055     \n",
      "Epoch 93/100\n",
      "398/398 [==============================] - 0s - loss: 0.6696 - acc: 0.6055     \n",
      "Epoch 94/100\n",
      "398/398 [==============================] - 0s - loss: 0.6696 - acc: 0.6055     \n",
      "Epoch 95/100\n",
      "398/398 [==============================] - 0s - loss: 0.6696 - acc: 0.6055     \n",
      "Epoch 96/100\n",
      "398/398 [==============================] - 0s - loss: 0.6696 - acc: 0.6055     \n",
      "Epoch 97/100\n",
      "398/398 [==============================] - 0s - loss: 0.6696 - acc: 0.6055     \n",
      "Epoch 98/100\n",
      "398/398 [==============================] - 0s - loss: 0.6696 - acc: 0.6055     \n",
      "Epoch 99/100\n",
      "398/398 [==============================] - 0s - loss: 0.6695 - acc: 0.6055     \n",
      "Epoch 100/100\n",
      "398/398 [==============================] - 0s - loss: 0.6695 - acc: 0.6055     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25ee2f459b0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size = 50, epochs = 100, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Evaluation\n",
    "- Keras model can be evaluated with evaluate() function\n",
    "- Evaluation results are contained in a list\n",
    "    - Doc (metrics): https://keras.io/metrics/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 32/171 [====>.........................] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'acc']\n",
      "[0.63870607063784235, 0.67836257240228481]\n"
     ]
    }
   ],
   "source": [
    "print(model.metrics_names)     # list of metric names the model is employing\n",
    "print(results)                 # actual figure of metrics computed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.638706070638\n",
      "accuracy:  0.678362572402\n"
     ]
    }
   ],
   "source": [
    "print('loss: ', results[0])\n",
    "print('accuracy: ', results[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention in Neural Networks\n",
    "- The idea of attention is straightforward; choose a specific area of interest to \"attend\" when classifying\n",
    "- Widely applied in neural machine translation, image captioning, speech recognition, etc.\n",
    "- source code here is mostly derived from below \n",
    "    - https://github.com/philipperemy/keras-attention-mechanism\n",
    "<br>\n",
    "<img src=\"https://ai2-s2-public.s3.amazonaws.com/figures/2016-11-08/060e380b28be29b7eda509981a50b4406ea6b21b/3-Figure2-1.png\" style=\"width: 500px\"/>\n",
    "\n",
    "Attention can be regarded as \"alignment\" in machine translation context\n",
    "</br>\n",
    "    \n",
    "    \n",
    "<br>\n",
    "<img src=\"https://cdn-images-1.medium.com/max/2000/1*ribYYJAU7EPdZtHFr0NDHw.png\" style=\"width: 700px\"/>\n",
    "\n",
    "Visualizing attention in image captioning process\n",
    "</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset\n",
    "- Digits dataset in sklearn\n",
    "- http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, concatenate, multiply, Dense, Permute, Reshape, LSTM, Activation\n",
    "from keras import optimizers\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "import keras.backend as K\n",
    "\n",
    "from IPython.display import SVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_data = data.images\n",
    "y_data = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_data = X_data.reshape(X_data.shape[0], 64)\n",
    "y_data = to_categorical(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size = 0.2, random_state = 777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1437, 64)\n",
      "(360, 64)\n",
      "(1437, 10)\n",
      "(360, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention with MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def attention_mlp():\n",
    "    input_layer = Input(shape = (X_train.shape[1],))\n",
    "    attention_probs = Dense(X_train.shape[1], activation = 'softmax', name='attention_vec')(input_layer)    # attention vector is achieved here\n",
    "    attention_mul = multiply([input_layer, attention_probs], name='attention_mul')\n",
    "    \n",
    "    attention_mul = Dense(50)(attention_mul)\n",
    "    output_layer = Dense(10, activation = 'softmax')(attention_mul)\n",
    "    \n",
    "    model = Model(inputs = [input_layer], outputs = output_layer)\n",
    "    adam = optimizers.Adam(lr = 0.001)\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = adam, metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = attention_mlp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_5 (InputLayer)             (None, 64)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "attention_vec (Dense)            (None, 64)            4160        input_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "attention_mul (Multiply)         (None, 64)            0           input_5[0][0]                    \n",
      "                                                                   attention_vec[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_9 (Dense)                  (None, 50)            3250        attention_mul[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_10 (Dense)                 (None, 10)            510         dense_9[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 7,920\n",
      "Trainable params: 7,920\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"337pt\" viewBox=\"0.00 0.00 193.00 337.00\" width=\"193pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 333)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-333 189,-333 189,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 2166470488976 -->\n",
       "<g class=\"node\" id=\"node1\"><title>2166470488976</title>\n",
       "<polygon fill=\"none\" points=\"50,-292.5 50,-328.5 176,-328.5 176,-292.5 50,-292.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"113\" y=\"-306.8\">input_5: InputLayer</text>\n",
       "</g>\n",
       "<!-- 2166475681296 -->\n",
       "<g class=\"node\" id=\"node2\"><title>2166475681296</title>\n",
       "<polygon fill=\"none\" points=\"0,-219.5 0,-255.5 132,-255.5 132,-219.5 0,-219.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"66\" y=\"-233.8\">attention_vec: Dense</text>\n",
       "</g>\n",
       "<!-- 2166470488976&#45;&gt;2166475681296 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>2166470488976-&gt;2166475681296</title>\n",
       "<path d=\"M101.623,-292.313C96.0227,-283.853 89.1581,-273.484 82.9547,-264.112\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"85.711,-261.935 77.2726,-255.529 79.874,-265.799 85.711,-261.935\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2166470089360 -->\n",
       "<g class=\"node\" id=\"node3\"><title>2166470089360</title>\n",
       "<polygon fill=\"none\" points=\"41,-146.5 41,-182.5 185,-182.5 185,-146.5 41,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"113\" y=\"-160.8\">attention_mul: Multiply</text>\n",
       "</g>\n",
       "<!-- 2166470488976&#45;&gt;2166470089360 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>2166470488976-&gt;2166470089360</title>\n",
       "<path d=\"M124.888,-292.046C131.014,-281.988 137.846,-268.827 141,-256 144.926,-240.031 144.926,-234.969 141,-219 138.709,-209.68 134.475,-200.185 129.982,-191.83\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"132.901,-189.885 124.888,-182.954 126.83,-193.369 132.901,-189.885\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2166475681296&#45;&gt;2166470089360 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>2166475681296-&gt;2166470089360</title>\n",
       "<path d=\"M77.3774,-219.313C82.9773,-210.853 89.8419,-200.484 96.0453,-191.112\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"99.126,-192.799 101.727,-182.529 93.289,-188.935 99.126,-192.799\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2166470519888 -->\n",
       "<g class=\"node\" id=\"node4\"><title>2166470519888</title>\n",
       "<polygon fill=\"none\" points=\"61,-73.5 61,-109.5 165,-109.5 165,-73.5 61,-73.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"113\" y=\"-87.8\">dense_9: Dense</text>\n",
       "</g>\n",
       "<!-- 2166470089360&#45;&gt;2166470519888 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>2166470089360-&gt;2166470519888</title>\n",
       "<path d=\"M113,-146.313C113,-138.289 113,-128.547 113,-119.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"116.5,-119.529 113,-109.529 109.5,-119.529 116.5,-119.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2166470489424 -->\n",
       "<g class=\"node\" id=\"node5\"><title>2166470489424</title>\n",
       "<polygon fill=\"none\" points=\"57.5,-0.5 57.5,-36.5 168.5,-36.5 168.5,-0.5 57.5,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"113\" y=\"-14.8\">dense_10: Dense</text>\n",
       "</g>\n",
       "<!-- 2166470519888&#45;&gt;2166470489424 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>2166470519888-&gt;2166470489424</title>\n",
       "<path d=\"M113,-73.3129C113,-65.2895 113,-55.5475 113,-46.5691\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"116.5,-46.5288 113,-36.5288 109.5,-46.5289 116.5,-46.5288\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In other words, attention mechanism can be explained as multiplying input nodes and softmax probabilities of each node elementwise\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f86b8a8d68>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([X_train], y_train, epochs = 50, batch_size = 50, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to obtain activation of each layer\n",
    "def get_activations(model, inputs, print_shape_only=False, layer_name=None):\n",
    "    # Documentation is available online on Github at the address below.\n",
    "    # From: https://github.com/philipperemy/keras-visualize-activations\n",
    "    print('----- activations -----')\n",
    "    activations = []\n",
    "    inp = model.input\n",
    "    if layer_name is None:\n",
    "        outputs = [layer.output for layer in model.layers]\n",
    "    else:\n",
    "        outputs = [layer.output for layer in model.layers if layer.name == layer_name]  # all layer outputs\n",
    "    funcs = [K.function([inp] + [K.learning_phase()], [out]) for out in outputs]  # evaluation functions\n",
    "    layer_outputs = [func([inputs, 1.])[0] for func in funcs]\n",
    "    for layer_activations in layer_outputs:\n",
    "        activations.append(layer_activations)\n",
    "        if print_shape_only:\n",
    "            print(layer_activations.shape)\n",
    "        else:\n",
    "            print(layer_activations)\n",
    "    return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- activations -----\n",
      "(1, 64)\n",
      "(1, 64)\n",
      "(1, 64)\n",
      "(1, 50)\n",
      "(1, 10)\n"
     ]
    }
   ],
   "source": [
    "attention_vector = get_activations(model,[X_train[0]], print_shape_only =True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n9l+8Q5/pEyhkXAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f85add51d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label:  0\n"
     ]
    }
   ],
   "source": [
    "plt.imshow(data.images[0])    # show first number in the dataset\n",
    "plt.show()\n",
    "print('label: ', data.target[0])    # label = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMQIHEiNwIDECBxL7H0kDm5BlTEEeAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f861f7ab38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "attention_vector = attention_vector.reshape(8,8)\n",
    "plt.imshow(attention_vector)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X7 = []\n",
    "for i in range(len(X_train)):\n",
    "    if y_train[i][7] == 1:\n",
    "        X7.append(X_train[i])\n",
    "X7 = np.array(X7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(140, 64)\n"
     ]
    }
   ],
   "source": [
    "print(X7.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- activations -----\n",
      "(140, 64)\n",
      "(140, 64)\n",
      "(140, 64)\n",
      "(140, 50)\n",
      "(140, 10)\n",
      "(140, 64)\n"
     ]
    }
   ],
   "source": [
    "attention_vector = get_activations(model, X7, print_shape_only =True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 8)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_vector = np.mean(attention_vector, axis = 0).reshape(8, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCBxIjMCBxP4LLEa0FBxKC8AAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f861f6a3c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(attention_vector)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, we could get a \"vague\" shape of \"7\" from our attention vector. This is where the model \"attend to\" when classifying the number 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2227297ccc0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAELCAYAAADJF31HAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ndBGRlFBAFxFJCQV0EZGU+P+mTQS4WvsdUQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22272981be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualizing activations in attention layer\n",
    "pd.DataFrame(attention_vector.flatten(), columns=['attention (%)']).plot(kind='bar',title='Attention Mechanism as a function of input dimensions.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention with LSTM\n",
    "\n",
    "<img src=\"https://github.com/philipperemy/keras-attention-mechanism/blob/master/assets/graph_multi_attention.png?raw=true\" style=\"width: 400px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reshape data into original 3-D shape\n",
    "X_data = X_data.reshape(X_data.shape[0], 8, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size = 0.2, random_state = 777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1437, 8, 8)\n",
      "(360, 8, 8)\n",
      "(1437, 10)\n",
      "(360, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = X_train.shape[2]\n",
    "TIME_STEPS = X_train.shape[1]\n",
    "\n",
    "# if True, the attention vector is shared across the input_dimensions where the attention is applied.\n",
    "SINGLE_ATTENTION_VECTOR = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def attention_3d_block(inputs):\n",
    "    # inputs.shape = (batch_size, time_steps, input_dim)\n",
    "    input_dim = int(inputs.shape[2])\n",
    "    a = Permute((2, 1))(inputs)\n",
    "    a = Reshape((input_dim, TIME_STEPS))(a) # this line is not useful. It's just to know which dimension is what.\n",
    "    a = Dense(TIME_STEPS, activation='softmax')(a)\n",
    "    if SINGLE_ATTENTION_VECTOR:\n",
    "        a = Lambda(lambda x: K.mean(x, axis=1), name='dim_reduction')(a)\n",
    "        a = RepeatVector(input_dim)(a)\n",
    "    a_probs = Permute((2, 1), name='attention_vec')(a)\n",
    "    output_attention_mul = multiply([inputs, a_probs], name='attention_mul')\n",
    "    return output_attention_mul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def attention_lstm():\n",
    "    inputs = Input(shape=(TIME_STEPS, INPUT_DIM,))\n",
    "    attention_mul = attention_3d_block(inputs)\n",
    "    lstm_units = 32\n",
    "    attention_mul = LSTM(lstm_units, return_sequences=False)(attention_mul)\n",
    "    output = Dense(10, activation='softmax')(attention_mul)\n",
    "    model = Model(inputs=[inputs], outputs=output)\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = attention_lstm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"556pt\" viewBox=\"0.00 0.00 201.50 556.00\" width=\"202pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 552)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-552 197.5,-552 197.5,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 2166425120328 -->\n",
       "<g class=\"node\" id=\"node1\"><title>2166425120328</title>\n",
       "<polygon fill=\"none\" points=\"65.5,-511.5 65.5,-547.5 191.5,-547.5 191.5,-511.5 65.5,-511.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"128.5\" y=\"-525.8\">input_3: InputLayer</text>\n",
       "</g>\n",
       "<!-- 2166371992520 -->\n",
       "<g class=\"node\" id=\"node2\"><title>2166371992520</title>\n",
       "<polygon fill=\"none\" points=\"14.5,-438.5 14.5,-474.5 142.5,-474.5 142.5,-438.5 14.5,-438.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"78.5\" y=\"-452.8\">permute_2: Permute</text>\n",
       "</g>\n",
       "<!-- 2166425120328&#45;&gt;2166371992520 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>2166425120328-&gt;2166371992520</title>\n",
       "<path d=\"M116.396,-511.313C110.378,-502.766 102.986,-492.269 96.3331,-482.823\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"99.1116,-480.69 90.4921,-474.529 93.3883,-484.72 99.1116,-480.69\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2166427113512 -->\n",
       "<g class=\"node\" id=\"node6\"><title>2166427113512</title>\n",
       "<polygon fill=\"none\" points=\"49.5,-146.5 49.5,-182.5 193.5,-182.5 193.5,-146.5 49.5,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"121.5\" y=\"-160.8\">attention_mul: Multiply</text>\n",
       "</g>\n",
       "<!-- 2166425120328&#45;&gt;2166427113512 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>2166425120328-&gt;2166427113512</title>\n",
       "<path d=\"M137.202,-511.263C149.766,-484.735 171.5,-431.985 171.5,-384.5 171.5,-384.5 171.5,-384.5 171.5,-309.5 171.5,-268.307 166.176,-257.49 151.5,-219 147.934,-209.647 142.942,-199.949 138.052,-191.421\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"140.981,-189.5 132.858,-182.698 134.966,-193.081 140.981,-189.5\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2166371716512 -->\n",
       "<g class=\"node\" id=\"node3\"><title>2166371716512</title>\n",
       "<polygon fill=\"none\" points=\"10.5,-365.5 10.5,-401.5 138.5,-401.5 138.5,-365.5 10.5,-365.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"74.5\" y=\"-379.8\">reshape_2: Reshape</text>\n",
       "</g>\n",
       "<!-- 2166371992520&#45;&gt;2166371716512 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>2166371992520-&gt;2166371716512</title>\n",
       "<path d=\"M77.5317,-438.313C77.0797,-430.289 76.5308,-420.547 76.025,-411.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"79.5164,-411.316 75.4594,-401.529 72.5275,-411.71 79.5164,-411.316\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2166372037632 -->\n",
       "<g class=\"node\" id=\"node4\"><title>2166372037632</title>\n",
       "<polygon fill=\"none\" points=\"20.5,-292.5 20.5,-328.5 124.5,-328.5 124.5,-292.5 20.5,-292.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"72.5\" y=\"-306.8\">dense_5: Dense</text>\n",
       "</g>\n",
       "<!-- 2166371716512&#45;&gt;2166372037632 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>2166371716512-&gt;2166372037632</title>\n",
       "<path d=\"M74.0159,-365.313C73.7898,-357.289 73.5154,-347.547 73.2625,-338.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"76.76,-338.426 72.9797,-328.529 69.7627,-338.623 76.76,-338.426\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2166435982360 -->\n",
       "<g class=\"node\" id=\"node5\"><title>2166435982360</title>\n",
       "<polygon fill=\"none\" points=\"0,-219.5 0,-255.5 143,-255.5 143,-219.5 0,-219.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"71.5\" y=\"-233.8\">attention_vec: Permute</text>\n",
       "</g>\n",
       "<!-- 2166372037632&#45;&gt;2166435982360 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>2166372037632-&gt;2166435982360</title>\n",
       "<path d=\"M72.2579,-292.313C72.1449,-284.289 72.0077,-274.547 71.8813,-265.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"75.3804,-265.479 71.7398,-255.529 68.3811,-265.577 75.3804,-265.479\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2166435982360&#45;&gt;2166427113512 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>2166435982360-&gt;2166427113512</title>\n",
       "<path d=\"M83.6036,-219.313C89.6224,-210.766 97.0144,-200.269 103.667,-190.823\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"106.612,-192.72 109.508,-182.529 100.888,-188.69 106.612,-192.72\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2166427115416 -->\n",
       "<g class=\"node\" id=\"node7\"><title>2166427115416</title>\n",
       "<polygon fill=\"none\" points=\"72.5,-73.5 72.5,-109.5 170.5,-109.5 170.5,-73.5 72.5,-73.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"121.5\" y=\"-87.8\">lstm_2: LSTM</text>\n",
       "</g>\n",
       "<!-- 2166427113512&#45;&gt;2166427115416 -->\n",
       "<g class=\"edge\" id=\"edge7\"><title>2166427113512-&gt;2166427115416</title>\n",
       "<path d=\"M121.5,-146.313C121.5,-138.289 121.5,-128.547 121.5,-119.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"125,-119.529 121.5,-109.529 118,-119.529 125,-119.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 2166435469184 -->\n",
       "<g class=\"node\" id=\"node8\"><title>2166435469184</title>\n",
       "<polygon fill=\"none\" points=\"69.5,-0.5 69.5,-36.5 173.5,-36.5 173.5,-0.5 69.5,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"121.5\" y=\"-14.8\">dense_6: Dense</text>\n",
       "</g>\n",
       "<!-- 2166427115416&#45;&gt;2166435469184 -->\n",
       "<g class=\"edge\" id=\"edge8\"><title>2166427115416-&gt;2166435469184</title>\n",
       "<path d=\"M121.5,-73.3129C121.5,-65.2895 121.5,-55.5475 121.5,-46.5691\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"125,-46.5288 121.5,-36.5288 118,-46.5289 125,-46.5288\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_3 (InputLayer)             (None, 8, 8)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "permute_2 (Permute)              (None, 8, 8)          0           input_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)              (None, 8, 8)          0           permute_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 8, 8)          72          reshape_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "attention_vec (Permute)          (None, 8, 8)          0           dense_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "attention_mul (Multiply)         (None, 8, 8)          0           input_3[0][0]                    \n",
      "                                                                   attention_vec[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                    (None, 32)            5248        attention_mul[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_6 (Dense)                  (None, 10)            330         lstm_2[0][0]                     \n",
      "====================================================================================================\n",
      "Total params: 5,650\n",
      "Trainable params: 5,650\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f86976bcc0>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([X_train], y_train, epochs = 100, batch_size = 64, validation_split = 0.3, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- activations -----\n",
      "(1, 8, 8)\n"
     ]
    }
   ],
   "source": [
    "attention_vector = get_activations(model, [X_train[0]], print_shape_only=True, layer_name = 'attention_vec')[0].reshape(8,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niRE4kBiBA4kROJAYgQOJETiQGIEDif0HmLHEfpXznWIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f86973df98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(attention_vector)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

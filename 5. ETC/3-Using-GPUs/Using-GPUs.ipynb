{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.1"},"colab":{"name":"Using-GPUs.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"DeoQ86zulk0W"},"source":["# Using GPUs\n","- Training on GPUs (graphic cards) makes training neural networks much faster than running on CPUs\n","- Keras supports training on GPUs with both Tensorflow & Theano backend\n","    - docs: https://keras.io/getting-started/faq/#how-can-i-run-keras-on-gpu\n","\n","\n","<br>\n","<img src=\"https://blogs.nvidia.com/wp-content/uploads/2016/03/titanxfordeeplearning.png\" style=\"width: 600px\"/>"]},{"cell_type":"markdown","metadata":{"id":"LLVjutQIlk0Z"},"source":["## Installation and checkups \n","- First, download and install **CUDA & CuDNN** (assuming that you are using NVIDIA gpus)\n","    - Note: Installing CuDNN will enable you to use CuDNNGRU & CuDNNLSTM layers, which is about x10 times faster than GRU & LSTM layers (for more information, refer to: [CuDNN layers](https://github.com/buomsoo-kim/Easy-deep-learning-with-Keras/tree/master/3.%20RNN/4-Advanced-RNN-3))\n","          - doc: https://keras.io/layers/recurrent/#cudnngru\n","          - doc: https://keras.io/layers/recurrent/#cudnnlstm\n","    - url: https://developer.nvidia.com/cudnn\n","- Then, install **tensorflow-gpu** (gpu-enabled version of Tensorflow) by typing below in cmd or terminal\n","    - pip install tensorflow-gpu\n","- Then check if your machine is utilizing GPU device\n","    - In my case, I have one GPU device (whose name is \"/device:GPU:0\")\n","\n","- **If you are using Google Colab, which is highly recommended to run these tutorials, just change the runtime type to \"GPU\".**"]},{"cell_type":"code","metadata":{"id":"X4n0BGUulk0a","executionInfo":{"status":"ok","timestamp":1605304265147,"user_tz":420,"elapsed":7105,"user":{"displayName":"Buomsoo Kim","photoUrl":"","userId":"18268696804115368229"}},"outputId":"dfd7a99f-1c72-49aa-a967-687a9dcbdcd0","colab":{"base_uri":"https://localhost:8080/"}},"source":["import tensorflow as tf\n","from tensorflow.python.client import device_lib\n","device_lib.list_local_devices()"],"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[name: \"/device:CPU:0\"\n"," device_type: \"CPU\"\n"," memory_limit: 268435456\n"," locality {\n"," }\n"," incarnation: 11928121271319414455, name: \"/device:XLA_CPU:0\"\n"," device_type: \"XLA_CPU\"\n"," memory_limit: 17179869184\n"," locality {\n"," }\n"," incarnation: 6816745644761666641\n"," physical_device_desc: \"device: XLA_CPU device\", name: \"/device:XLA_GPU:0\"\n"," device_type: \"XLA_GPU\"\n"," memory_limit: 17179869184\n"," locality {\n"," }\n"," incarnation: 18251884735093207511\n"," physical_device_desc: \"device: XLA_GPU device\", name: \"/device:GPU:0\"\n"," device_type: \"GPU\"\n"," memory_limit: 14640891840\n"," locality {\n","   bus_id: 1\n","   links {\n","   }\n"," }\n"," incarnation: 16291250154431907399\n"," physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"]"]},"metadata":{"tags":[]},"execution_count":1}]}]}